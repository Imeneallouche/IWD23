{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#from openai_secret_manager import get_secret\n",
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "\n",
    "# replace YOUR_API_KEY with your actual API key for the ChatGPT service\n",
    "\n",
    "\n",
    "#exit responses\n",
    "exiting = [\"by\", \"bye\", \"quit\" , \"exit\" , \"stop\"]\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "with open(\"mental_health_emotional.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the patterns and responses from the dataset\n",
    "patterns = []\n",
    "responses = []  \n",
    "tags = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        patterns.append(pattern)\n",
    "        responses.append(intent[\"responses\"])\n",
    "        tags.append(intent[\"tag\"])\n",
    "\n",
    "# Tokenize the patterns\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(patterns)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Pad the tokenized sequences\n",
    "max_sequence_length = max([len(pattern.split()) for pattern in patterns])\n",
    "padded_sequences = pad_sequences(tokenizer.texts_to_sequences(patterns), \n",
    "                                 maxlen=max_sequence_length, padding=\"post\")\n",
    "\n",
    "# Convert the tags to one-hot encodings\n",
    "tag_set = set(tags)\n",
    "tag_indices = dict((tag, index) for index, tag in enumerate(tag_set))\n",
    "one_hot_tags = keras.utils.to_categorical([tag_indices[tag] for tag in tags])\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(input_dim=len(word_index) + 1, output_dim=128),\n",
    "    layers.Bidirectional(layers.LSTM(128, dropout=0.2, return_sequences=True)),\n",
    "    layers.Bidirectional(layers.LSTM(64, dropout=0.2)),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(tag_set), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences, one_hot_tags, epochs=50, batch_size=32)\n",
    "\n",
    "# Define a function to predict the response\n",
    "def predict_response(input_text):\n",
    "    # Tokenize the input text and pad the sequence\n",
    "    sequence = tokenizer.texts_to_sequences([input_text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length, padding=\"post\")\n",
    "    \n",
    "    # Make a prediction using the model\n",
    "    prediction = model.predict(padded_sequence)[0]\n",
    "    \n",
    "    # Select a random response from the predicted tag's responses\n",
    "    tag_index = np.argmax(prediction)\n",
    "    tag = list(tag_indices.keys())[list(tag_indices.values()).index(tag_index)]\n",
    "    responses = data[\"intents\"][tag_index][\"responses\"]\n",
    "    response = random.choice(responses)\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"Hello! How can I assist you today?\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \").lower()\n",
    "        if user_input in exiting:\n",
    "            print(\"Goodbye! Take care.\")\n",
    "            break\n",
    "        response = predict_response(user_input)\n",
    "        print(response)\n",
    "\n",
    "chat()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
